{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output, State, ctx\n",
    "import dash_bootstrap_components as dbc\n",
    "import os\n",
    "import joblib\n",
    "import sklearn\n",
    "import openrouteservice\n",
    "from openrouteservice import convert\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "# File paths for data \n",
    "# The Analyzed folder must be downloaded before running. See README for more information\n",
    "CSV_FILE_PATH = (\"Data/Analyzed/TripData_2011.csv\", \"Data/Analyzed/TripData_2012.csv\", \"Data/Analyzed/TripData_2013.csv\", \"Data/Analyzed/TripData_2014.csv\",\n",
    "                \"Data/Analyzed/TripData_2015.csv\", \"Data/Analyzed/TripData_2016.csv\", \"Data/Analyzed/TripData_2017.csv\", \"Data/Analyzed/TripData_2018.csv\",\n",
    "                \"Data/Analyzed/TripData_2019.csv\", \"Data/Analyzed/TripData_2020.csv\", \"Data/Analyzed/TripData_2021.csv\", \"Data/Analyzed/TripData_2022.csv\",\n",
    "                \"Data/Analyzed/TripData_2023.csv\", \"Data/Analyzed/TripData_2024.csv\")\n",
    "SHAPEFILE_PATH = \"taxi_zones/taxi_zones.shp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize client with ORS API key\n",
    "# The MLP model will not operate without an active key. Visit https://api.openrouteservice.org to \n",
    "# sign up and get a free API key\n",
    "ors_status_msg = \"‚úÖ ORS Client successfully initialized\"\n",
    "\n",
    "# Insert key here\n",
    "ors_key = \"YOUR KEY HERE\"\n",
    "try:\n",
    "    client = openrouteservice.Client(key=ors_key)\n",
    "    # Test to ensure that API key is valid\n",
    "    coords = [[8.681495, 49.41461], [8.687872, 49.420318]]\n",
    "    client.directions(coordinates=coords, profile=\"driving-car\")\n",
    "    ors_client = client\n",
    "except Exception as e:\n",
    "    ors_status_msg = f\"‚ùå ORS Client failed to initialize: {str(e)}. Please enter valid ORS key before proceeding\"\n",
    "\n",
    "print(ors_status_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load in MLP Models ---\n",
    "\n",
    "# Load in MLP models for the scatter map\n",
    "\n",
    "mlp_models = {\n",
    "    # Fare models\n",
    "    \"mlp_fare_2011\": joblib.load(\"Models/model_2011_fare.pkl\"),\n",
    "    \"mlp_fare_2012\": joblib.load(\"Models/model_2012_fare.pkl\"),\n",
    "    \"mlp_fare_2013\": joblib.load(\"Models/model_2013_fare.pkl\"),\n",
    "    \"mlp_fare_2014\": joblib.load(\"Models/model_2014_fare.pkl\"),\n",
    "    \"mlp_fare_2015\": joblib.load(\"Models/model_2015_fare.pkl\"),\n",
    "    \"mlp_fare_2016\": joblib.load(\"Models/model_2016_fare.pkl\"),\n",
    "    \"mlp_fare_2017\": joblib.load(\"Models/model_2017_fare.pkl\"),\n",
    "    \"mlp_fare_2018\": joblib.load(\"Models/model_2018_fare.pkl\"),\n",
    "    \"mlp_fare_2019\": joblib.load(\"Models/model_2019_fare.pkl\"),\n",
    "    \"mlp_fare_2020\": joblib.load(\"Models/model_2020_fare.pkl\"),\n",
    "    \"mlp_fare_2021\": joblib.load(\"Models/model_2021_fare.pkl\"),\n",
    "    \"mlp_fare_2022\": joblib.load(\"Models/model_2022_fare.pkl\"),\n",
    "    \"mlp_fare_2023\": joblib.load(\"Models/model_2023_fare.pkl\"),\n",
    "    \"mlp_fare_2024\": joblib.load(\"Models/model_2024_fare.pkl\"),\n",
    "\n",
    "    # Time models\n",
    "    \"mlp_time_2011\": joblib.load(\"Models/model_2011_time.pkl\"),\n",
    "    \"mlp_time_2013\": joblib.load(\"Models/model_2013_time.pkl\"),\n",
    "    \"mlp_time_2014\": joblib.load(\"Models/model_2014_time.pkl\"),\n",
    "    \"mlp_time_2015\": joblib.load(\"Models/model_2015_time.pkl\"),\n",
    "    \"mlp_time_2016\": joblib.load(\"Models/model_2016_time.pkl\"),\n",
    "    \"mlp_time_2017\": joblib.load(\"Models/model_2017_time.pkl\"),\n",
    "    \"mlp_time_2018\": joblib.load(\"Models/model_2018_time.pkl\"),\n",
    "    \"mlp_time_2019\": joblib.load(\"Models/model_2019_time.pkl\"),\n",
    "    \"mlp_time_2020\": joblib.load(\"Models/model_2020_time.pkl\"),\n",
    "    \"mlp_time_2021\": joblib.load(\"Models/model_2021_time.pkl\"),\n",
    "    \"mlp_time_2022\": joblib.load(\"Models/model_2022_time.pkl\"),\n",
    "    \"mlp_time_2023\": joblib.load(\"Models/model_2023_time.pkl\"),\n",
    "    \"mlp_time_2024\": joblib.load(\"Models/model_2024_time.pkl\")\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Loading and Preprocessing ---\n",
    "def load_and_prepare_data(csv_path, shp_path):\n",
    "    \"\"\"\n",
    "    Loads taxi trip data and shapefiles, merges them, calculates zone statistics,\n",
    "    and prepares data for scatter plot.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the taxi trip data CSV file.\n",
    "        shp_path (str): Path to the taxi zones shapefile.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - geopandas.GeoDataFrame: GeoDataFrame with aggregated statistics per zone per time zone (for map/bars).\n",
    "            - pd.DataFrame: DataFrame containing relevant columns from original trips for scatter plot.\n",
    "            - list: A list of unique time zones found in the data.\n",
    "            Returns (None, None, None) if file loading fails.\n",
    "    \"\"\"\n",
    "    stats_gdf = GeoDataFrame()\n",
    "    scatter_df = pd.DataFrame()\n",
    "    zone_gdf = GeoDataFrame()\n",
    "\n",
    "    for path in csv_path:\n",
    "        stats_gdf_prior = stats_gdf\n",
    "        scatter_df_prior = scatter_df\n",
    "        zone_gdf_prior = zone_gdf\n",
    "        \n",
    "        # --- Load Trip Data ---\n",
    "        print(f\"Loading trip data from: {path}\")\n",
    "        # Load columns needed for ALL visualizations \n",
    "        required_cols = [\n",
    "            'PULocationID', 'Trip_Time', 'Time Zone',\n",
    "            'trip_distance', 'fare_amount', 'cluster' # Added for scatter plot\n",
    "        ]\n",
    "        df_2024 = pd.read_csv(path, usecols=required_cols)\n",
    "        print(\"Unique pickup locations: \", len(df_2024['PULocationID'].unique()))\n",
    "\n",
    "        # --- Basic Cleaning (Original Data) ---\n",
    "        # Drop rows with NA in essential columns needed for filtering or plotting\n",
    "        essential_cols_for_scatter = ['PULocationID', 'Trip_Time', 'Time Zone', 'trip_distance', 'fare_amount', 'cluster']\n",
    "        df_2024 = df_2024.dropna(subset=essential_cols_for_scatter)\n",
    "        print(f\"Shape after dropping NA in essential columns: {df_2024.shape}\")\n",
    "\n",
    "        # Ensure cluster is treated as categorical for coloring\n",
    "        # Convert cluster to string if it's not already, to ensure discrete colors\n",
    "        if not pd.api.types.is_string_dtype(df_2024['cluster']):\n",
    "            print(\"Converting 'cluster' column to string type for discrete coloring.\")\n",
    "            df_2024['cluster'] = df_2024['cluster'].astype(str)\n",
    "\n",
    "\n",
    "        # Get unique time zones before aggregation\n",
    "        unique_time_zones = sorted(df_2024['Time Zone'].unique().tolist())\n",
    "        print(f\"Unique Time Zones found: {unique_time_zones}\")\n",
    "\n",
    "        # --- Load Shapefile ---\n",
    "        print(f\"Loading shapefile from: {shp_path}\")\n",
    "        gdf = gpd.read_file(shp_path)\n",
    "        gdf = gdf.to_crs('EPSG:4326') # Use standard EPSG code for WGS84 lat/lon\n",
    "        gdf = gdf[['LocationID', 'zone', 'borough', 'geometry']] # Keep geometry for aggregated stats\n",
    "\n",
    "        # --- Merge Trip Data with Geometry/Zone Info ---\n",
    "        print(\"Merging trip data and shapefile...\")\n",
    "        # Merge to add borough and zone name to each trip record\n",
    "        # Use inner merge to only keep trips starting in valid zones defined in the shapefile\n",
    "        merged_df = gdf.merge(df_2024, left_on='LocationID', right_on='PULocationID', how='inner')\n",
    "        print(f\"Merge complete. Shape after merge: {merged_df.shape}\")\n",
    "        # Drop redundant/unneeded columns after merge\n",
    "        merged_df = merged_df.drop(columns=['PULocationID', 'LocationID']) # Keep zone, borough, geometry\n",
    "\n",
    "        # --- Get latitude and longitude for every zone for multi-layer perceptron models\n",
    "\n",
    "        # Load in WGS84 for later mapping\n",
    "        zone_gdf = gpd.read_file(\"taxi_zones/taxi_zones.shp\")\n",
    "\n",
    "        # Step 1: Reproject to a projected CRS for accurate geometry operations\n",
    "        projected = zone_gdf.to_crs(epsg=2263)  # NY State Plane (feet)\n",
    "\n",
    "        # Step 2: Calculate centroids in projected CRS\n",
    "        projected['centroid'] = projected.geometry.centroid\n",
    "\n",
    "        # Step 3: Convert centroids back to lat/lon (WGS84)\n",
    "        centroids = projected.set_geometry('centroid').to_crs(epsg=4326)\n",
    "\n",
    "        # Step 4: Add lat/lon to original zone_gdf\n",
    "        zone_gdf['lat'] = centroids.geometry.y\n",
    "        zone_gdf['lon'] = centroids.geometry.x\n",
    "\n",
    "        # --- Prepare Data for Scatter Plot ---\n",
    "        # Select only the columns needed for filtering and the scatter plot itself\n",
    "        # Keep 'borough' and 'Time Zone' for filtering in the callback\n",
    "        scatter_cols = ['trip_distance', 'Trip_Time', 'fare_amount', 'cluster', 'borough', 'Time Zone']\n",
    "        # Create scatter_df from the merged data \n",
    "        scatter_df = merged_df[scatter_cols].copy()\n",
    "        print(f\"Scatter plot data prepared. Shape: {scatter_df.shape}\")\n",
    "\n",
    "\n",
    "        # --- Prepare Aggregated Data for Map/Bar Chart ---\n",
    "        print(\"Calculating aggregated statistics per zone and time zone...\")\n",
    "        # Group the merged data by zone, borough, LocationID, geometry AND Time Zone\n",
    "        # Use the 'merged_df' which already has geometry associated\n",
    "        zone_time_stats = merged_df.groupby(['zone', 'borough', 'geometry', 'Time Zone'])['Trip_Time'].agg(['mean', 'count', 'median']).reset_index()\n",
    "        print(f\"Zone-Time stats calculated. Shape: {zone_time_stats.shape}\")\n",
    "\n",
    "        # Create the final GeoDataFrame directly from aggregated stats\n",
    "        stats_gdf = GeoDataFrame(zone_time_stats, geometry='geometry', crs='EPSG:4326')\n",
    "        print(\"Aggregated GeoDataFrame created.\")\n",
    "\n",
    "        scatter_df = pd.concat([scatter_df_prior, scatter_df])\n",
    "        stats_gdf = pd.concat([stats_gdf_prior, stats_gdf])\n",
    "        zone_gdf = pd.concat([zone_gdf_prior, zone_gdf])\n",
    "\n",
    "    # Return aggregated stats, scatter data, and time zones \n",
    "    return stats_gdf, scatter_df, unique_time_zones, zone_gdf\n",
    "\n",
    "# --- Load Data ---\n",
    "zone_time_stats_gdf, scatter_data_df, time_zones, zone_gdf = load_and_prepare_data(CSV_FILE_PATH, SHAPEFILE_PATH)\n",
    "\n",
    "# Check if data loading was successful\n",
    "if zone_time_stats_gdf is None or scatter_data_df is None:\n",
    "    print(\"Exiting: Data loading failed.\")\n",
    "    exit() \n",
    "\n",
    "# Get unique boroughs for the filter dropdown, including an 'All' option\n",
    "all_boroughs = ['All'] + sorted(zone_time_stats_gdf['borough'].unique().tolist())\n",
    "\n",
    "# Prepare time zone options for dropdown\n",
    "all_time_zones = ['All'] + time_zones\n",
    "\n",
    "# Dropdown options for years 2011-2024\n",
    "year_options = [{'label': str(year), 'value': year} for year in range(2011, 2025)]\n",
    "\n",
    "\n",
    "# --- Dash App Initialization ---\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "server = app.server # Expose server for deployment\n",
    "\n",
    "# --- App Layout ---\n",
    "app.layout = dbc.Container([\n",
    "    dbc.Row(\n",
    "        dbc.Col(html.H1(\"NYC Taxi Trip Analysis (2024)\", className=\"text-center my-4\"), width=12)\n",
    "    ),\n",
    "    dbc.Row([\n",
    "        # Left Column: Map and Filters\n",
    "        dbc.Col([\n",
    "            dbc.Alert(\"Data limited to January 2024.\", color=\"#e3e3e3\", className=\"mb-4\"),\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Filters\"),\n",
    "                dbc.CardBody([\n",
    "                    html.Label(\"Select Borough:\"),\n",
    "                    dcc.Dropdown(\n",
    "                        id='borough-filter',\n",
    "                        options=[{'label': b, 'value': b} for b in all_boroughs],\n",
    "                        value='All', clearable=False, className=\"mb-3\"\n",
    "                    ),\n",
    "                    html.Label(\"Select Time Zone:\"),\n",
    "                    dcc.Dropdown(\n",
    "                        id='time-zone-filter',\n",
    "                        options=[{'label': tz, 'value': tz} for tz in all_time_zones],\n",
    "                        value='All', clearable=False, className=\"mb-3\"\n",
    "                    ),\n",
    "                ]),\n",
    "            ], className=\"mb-4\"),\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Average Trip Time by Zone\"),\n",
    "                dbc.CardBody([\n",
    "                    dcc.Graph(id='choropleth-map', config={'displayModeBar': False})\n",
    "                ])\n",
    "            ]),\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Multi Layer Perceptron Visualization for Estimated Fare per Mile and Estimated Trip Distance\"),\n",
    "                dbc.CardBody([\n",
    "                    # First row: status + pickup/dropoff summary\n",
    "                    dbc.Row([\n",
    "                        dbc.Col(html.Div(id=\"ors-status\", children=html.Div(ors_status_msg)), width=4),\n",
    "                        dbc.Col(html.Div(id=\"pickup-output\"), width=4),\n",
    "                        dbc.Col(html.Div(id=\"dropoff-output\"), width=4),\n",
    "                    ], className=\"mb-3\"),\n",
    "                    # Dropdowns: year and time zone\n",
    "                    dbc.Row([\n",
    "                        dbc.Col([\n",
    "                            html.Label(\"Select Year:\"),\n",
    "                            dcc.Dropdown(id='year-filter', options=year_options, value=2024)\n",
    "                        ], width=6),\n",
    "                        dbc.Col([\n",
    "                            html.Label(\"Select Time Zone:\"),\n",
    "                            dcc.Dropdown(id='time-zone-mlp-filter', options=time_zones, value='Rush Hour')\n",
    "                        ], width=6),\n",
    "                    ], className=\"mb-3\"),\n",
    "                    # Reset button\n",
    "                    dbc.Row([\n",
    "                        dbc.Col(html.Button(\"Reset\", id=\"reset-btn\", n_clicks=0, className=\"btn btn-secondary\"), width=\"auto\")\n",
    "                    ], className=\"mb-4\"),\n",
    "                    dcc.Graph(id='mlp-map', config={'displayModeBar': False}),\n",
    "                    dcc.Store(id=\"selection-store\", data=[]),\n",
    "                    ])\n",
    "            ], className = \"mb-4\")\n",
    "        ], md=6),\n",
    "\n",
    "        # Right Column: Charts\n",
    "        dbc.Col([\n",
    "            # 3D plot\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Trip Cluster Visualization (Sample)\"), \n",
    "                dbc.CardBody([\n",
    "                    dcc.Graph(id='scatter-3d-plot', config={'displayModeBar': True})\n",
    "                ])\n",
    "            ], className=\"mb-4\"),\n",
    "\n",
    "            # Bar Chart \n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Number of Trips by Borough\"),\n",
    "                dbc.CardBody([\n",
    "                    dcc.Graph(id='bar-chart-trip-count', config={'displayModeBar': False})\n",
    "                ])\n",
    "            ]),\n",
    "        ], md=6),\n",
    "    ])\n",
    "], fluid=True)\n",
    "\n",
    "# --- Callbacks ---\n",
    "@app.callback(\n",
    "    [Output('choropleth-map', 'figure'),\n",
    "     Output('scatter-3d-plot', 'figure'), \n",
    "     Output('bar-chart-trip-count', 'figure')],\n",
    "    [Input('borough-filter', 'value'),\n",
    "     Input('time-zone-filter', 'value')]\n",
    ")\n",
    "\n",
    "def update_visualizations(selected_borough, selected_time_zone):\n",
    "    \"\"\"\n",
    "    Updates the choropleth map, 3D scatter plot, and trip count bar chart\n",
    "    based on the selected borough and time zone.\n",
    "\n",
    "    Args:\n",
    "        selected_borough (str): The borough selected in the dropdown filter.\n",
    "        selected_time_zone (str): The time zone selected in the dropdown filter.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the updated figures for the map, scatter plot, and count bar chart.\n",
    "    \"\"\"\n",
    "    # --- Filter Data ---\n",
    "    # Filter aggregated data for map\n",
    "    filtered_agg_gdf = zone_time_stats_gdf.copy()\n",
    "    # Filter unaggregated data for scatter plot\n",
    "    filtered_scatter_df = scatter_data_df.copy()\n",
    "\n",
    "    if selected_borough != 'All':\n",
    "        filtered_agg_gdf = filtered_agg_gdf[filtered_agg_gdf['borough'] == selected_borough]\n",
    "        # Filter scatter data based on borough\n",
    "        filtered_scatter_df = filtered_scatter_df[filtered_scatter_df['borough'] == selected_borough]\n",
    "\n",
    "    if selected_time_zone != 'All':\n",
    "        filtered_agg_gdf = filtered_agg_gdf[filtered_agg_gdf['Time Zone'] == selected_time_zone]\n",
    "        # Filter scatter data based on time zone\n",
    "        filtered_scatter_df = filtered_scatter_df[filtered_scatter_df['Time Zone'] == selected_time_zone]\n",
    "\n",
    "    # --- Prepare Figures ---\n",
    "    # Define layout for empty figures\n",
    "    empty_layout = go.Layout(title='No data for selected filters', xaxis={'visible': False}, yaxis={'visible': False}, paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)')\n",
    "    empty_fig = go.Figure(layout=empty_layout)\n",
    "\n",
    "\n",
    "    # --- Create Choropleth Map ---\n",
    "    # Aggregate results after filtering by Time Zone for the map\n",
    "    if filtered_agg_gdf.empty:\n",
    "         map_data_gdf = GeoDataFrame(columns=['zone', 'borough', 'geometry', 'total_count', 'weighted_mean_sum', 'median_time', 'final_mean_time'], geometry='geometry', crs='EPSG:4326')\n",
    "    else:\n",
    "        filtered_agg_gdf['weighted_mean_time'] = filtered_agg_gdf['mean'] * filtered_agg_gdf['count']\n",
    "        map_data_agg = filtered_agg_gdf.groupby(['zone', 'borough', 'geometry']).agg(\n",
    "            total_count=('count', 'sum'),\n",
    "            weighted_mean_sum=('weighted_mean_time', 'sum'),\n",
    "            median_time=('median', 'first')\n",
    "        ).reset_index()\n",
    "        map_data_agg['final_mean_time'] = map_data_agg['weighted_mean_sum'] / map_data_agg['total_count']\n",
    "        map_data_agg['final_mean_time'] = map_data_agg['final_mean_time'].fillna(0)\n",
    "        map_data_agg['median_time'] = map_data_agg['median_time'].fillna(0)\n",
    "        map_data_gdf = GeoDataFrame(map_data_agg, geometry='geometry', crs='EPSG:4326')\n",
    "\n",
    "    # Generate map figure or empty figure\n",
    "    if map_data_gdf.empty or map_data_gdf['total_count'].sum() == 0:\n",
    "        map_fig = go.Figure(layout=empty_layout.update(title='No map data for selected filters'))\n",
    "    else:\n",
    "        center_point = map_data_gdf.geometry.union_all().centroid\n",
    "        map_fig = px.choropleth_map(\n",
    "            map_data_gdf,\n",
    "            geojson=map_data_gdf.__geo_interface__,\n",
    "            color=\"final_mean_time\", locations=\"zone\", featureidkey=\"properties.zone\",\n",
    "            center={\"lat\": center_point.y, \"lon\": center_point.x},\n",
    "            zoom=9.8 if selected_borough == 'All' else 10.35,\n",
    "            color_continuous_scale=\"Viridis\",\n",
    "            range_color=[0, zone_time_stats_gdf['mean'].quantile(0.95) if not zone_time_stats_gdf.empty else 1],\n",
    "            labels={\"final_mean_time\": \"Avg. Trip Time (min)\", \"total_count\": \"Number of Trips\", \"median_time\": \"Median Trip Time (min)\", \"zone\": \"Zone\", \"borough\": \"Borough\"},\n",
    "            custom_data=['zone', 'borough', 'total_count', 'median_time']\n",
    "        )\n",
    "        map_fig.update_traces(\n",
    "            hovertemplate=\"<b>Zone: %{customdata[0]}</b><br>Borough: %{customdata[1]}<br>Avg. Trip Time: %{z:.1f} min<br>Number of Trips: %{customdata[2]}<br>Median Trip Time: %{customdata[3]:.1f} min<extra></extra>\",\n",
    "        )\n",
    "        map_fig.update_layout(\n",
    "            coloraxis_colorbar=dict(title=\"Avg. Time<br>(min)\"),\n",
    "            margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0},\n",
    "        )\n",
    "        map_fig.update_geos(visible=False, projection_type=\"mercator\")\n",
    "\n",
    "    # --- Create 3D Scatter Plot ---\n",
    "    # Generate scatter plot figure \n",
    "    if filtered_scatter_df.empty:\n",
    "        scatter_fig = go.Figure(layout=empty_layout.update(title='No scatter data for selected filters'))\n",
    "    else:\n",
    "        # Take a random sample (up to 1000 points) from the filtered data\n",
    "        sample_size = min(1000, len(filtered_scatter_df))\n",
    "        scatter_sample_df = filtered_scatter_df.sample(n=sample_size, random_state=42) # Use random_state for reproducibility\n",
    "        scatter_sample_df['cluster'] = [\"abnormal\" if int(x) == -1 else \"normal\" for x in scatter_sample_df['cluster']]\n",
    "        scatter_fig = px.scatter_3d(\n",
    "            scatter_sample_df,\n",
    "            x='trip_distance',\n",
    "            y='Trip_Time',\n",
    "            z='fare_amount',\n",
    "            color='cluster', # Color points by cluster ID\n",
    "            labels={ # More descriptive labels\n",
    "                'trip_distance': 'Trip Distance (miles)',\n",
    "                'Trip_Time': 'Trip Time (min)',\n",
    "                'fare_amount': 'Fare Amount ($)',\n",
    "                'cluster': 'Cluster ID'\n",
    "            },\n",
    "            title=f\"Trip Characteristics by Cluster (Sample: {sample_size} trips)\",\n",
    "            # Add hover data\n",
    "            hover_data=['borough', 'Time Zone']\n",
    "        )\n",
    "        scatter_fig.update_layout(\n",
    "             margin=dict(l=0, r=0, b=0, t=40), # Adjust top margin for title\n",
    "             legend_title_text='Cluster', # Explicitly set legend title\n",
    "             # Default eye position is often around x=1.25, y=1.25, z=1.25\n",
    "             scene_camera = dict(\n",
    "                  up=dict(x=0, y=0, z=1),          # Sets the 'up' direction (usually z-axis)\n",
    "                  center=dict(x=0, y=0, z=-0.5),      # Sets the point the camera looks at\n",
    "                  eye=dict(x=1.5, y=1.5, z=0.5)    # Sets the camera position (x, y, z)\n",
    "              )\n",
    "        )\n",
    "        # Make markers smaller\n",
    "        scatter_fig.update_traces(marker=dict(size=3.5))\n",
    "\n",
    "\n",
    "    # --- Create Bar Chart (Trip Count) ---\n",
    "    # Calculate borough stats based on the filtered *aggregated* data\n",
    "    if filtered_agg_gdf.empty:\n",
    "         borough_stats = pd.DataFrame(columns=['borough', 'count', 'mean']) # Empty DataFrame\n",
    "    else:\n",
    "        # Use the already calculated 'weighted_mean_time' and 'count' from filtered_agg_gdf\n",
    "        # Need to re-aggregate filtered_agg_gdf by borough for the bar chart\n",
    "        borough_agg = filtered_agg_gdf.groupby('borough').agg(\n",
    "            total_count = ('count', 'sum'),\n",
    "            weighted_mean_sum = ('weighted_mean_time', 'sum')\n",
    "        ).reset_index()\n",
    "\n",
    "        # Calculate weighted average time per borough\n",
    "        borough_agg['mean'] = borough_agg['weighted_mean_sum'] / borough_agg['total_count']\n",
    "        borough_agg['mean'] = borough_agg['mean'].fillna(0)\n",
    "\n",
    "        borough_stats = borough_agg[['borough', 'total_count', 'mean']].rename(columns={'total_count': 'count'})\n",
    "\n",
    "\n",
    "    # Generate count bar chart or empty figure\n",
    "    if borough_stats.empty or borough_stats['count'].sum() == 0:\n",
    "         bar_count_fig = go.Figure(layout=empty_layout.update(title='No count data for selected filters'))\n",
    "    else:\n",
    "        bar_count_fig = px.bar(\n",
    "            borough_stats,\n",
    "            x='borough', y='count',\n",
    "            labels={'count': 'Number of Trips', 'borough': 'Borough'},\n",
    "            color='borough', text='count'\n",
    "        )\n",
    "        bar_count_fig.update_traces(texttemplate='%{text:,}', textposition='outside')\n",
    "        bar_count_fig.update_layout(\n",
    "            xaxis_title=None, yaxis_title=\"Number of Trips\",\n",
    "            showlegend=False, margin=dict(t=20, b=0, l=0, r=0)\n",
    "        )\n",
    "        bar_count_fig.update_traces(\n",
    "            hovertemplate=\"<b>Borough: %{x}</b><br>Number of Trips: %{y:,}<extra></extra>\"\n",
    "        )\n",
    "\n",
    "    # *** MODIFICATION: Return map, scatter, and count figures ***\n",
    "    return map_fig, scatter_fig, bar_count_fig\n",
    "\n",
    "# Handle selection of pick-up/drop-off points and reset logic for mlp_map\n",
    "@app.callback(\n",
    "    Output(\"selection-store\", \"data\"),\n",
    "    Input(\"mlp-map\", \"clickData\"),\n",
    "    Input(\"reset-btn\", \"n_clicks\"),\n",
    "    Input(\"time-zone-mlp-filter\", \"value\"),\n",
    "    Input(\"year-filter\", \"value\"),\n",
    "    State(\"selection-store\", \"data\"),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def store_selection(clickData, reset_clicks, time_zone_clicks, year_clicks, current_selections):\n",
    "    trigger = ctx.triggered_id\n",
    "\n",
    "    # All selected points should be reset when any of these parameters are triggered/clicked\n",
    "    if trigger in [\"reset-btn\", 'time-zone-mlp-filter', \"year-filter\"]:\n",
    "        return []\n",
    "\n",
    "    # If a point on the mlp map has been clicked\n",
    "    if trigger == \"mlp-map\" and clickData and \"points\" in clickData:\n",
    "        point = clickData[\"points\"][0]\n",
    "        loc_id = point[\"hovertext\"]\n",
    "\n",
    "        # Get selected point and store it as either 1)pick-up or 2)drop-off\n",
    "        if loc_id not in current_selections:\n",
    "            return current_selections + [loc_id]\n",
    "        else:\n",
    "            return current_selections\n",
    "\n",
    "    return dash.no_update\n",
    "\n",
    "# Update map and display selected points\n",
    "@app.callback(\n",
    "    Output(\"mlp-map\", \"figure\"),\n",
    "    Output(\"pickup-output\", \"children\"),\n",
    "    Output(\"dropoff-output\", \"children\"),\n",
    "    Output(\"ors-status\", \"children\"),\n",
    "    Input(\"selection-store\", \"data\"),\n",
    "    Input(\"year-filter\", \"value\"),\n",
    "    Input(\"time-zone-mlp-filter\", \"value\")\n",
    "\n",
    ")\n",
    "def update_map_and_output(selections, year_selection, shift):\n",
    "\n",
    "    # Verify that points are actually populated\n",
    "    pickup = selections[0] if len(selections) > 0 else None\n",
    "    dropoff = selections[1] if len(selections) > 1 else None\n",
    "\n",
    "    # --- Create Scatter Map ---\n",
    "\n",
    "    # Create the figure using px.scatter_map\n",
    "    scatter_map_fig = px.scatter_map(\n",
    "        zone_gdf,\n",
    "        lat=\"lat\",\n",
    "        lon=\"lon\",\n",
    "        hover_name=\"zone\",\n",
    "        hover_data=[\"LocationID\", \"borough\"],\n",
    "        zoom=9,\n",
    "        height=700\n",
    "    )\n",
    "\n",
    "    scatter_map_fig.update_layout(\n",
    "        mapbox_style=\"carto-positron\",\n",
    "        margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0}\n",
    "    )\n",
    "\n",
    "    # If both points are selected, draw a line between them and call MLP algorithm\n",
    "    if pickup and dropoff:\n",
    "\n",
    "        # Get pickup and dropoff zones\n",
    "        pickup_row = zone_gdf[zone_gdf[\"zone\"] == pickup].iloc[0]\n",
    "        dropoff_row = zone_gdf[zone_gdf[\"zone\"] == dropoff].iloc[0]\n",
    "\n",
    "        # Coordinates must be in (lon, lat) format\n",
    "        pickup_coords = (pickup_row[\"lon\"], pickup_row[\"lat\"])\n",
    "        dropoff_coords = (dropoff_row[\"lon\"], dropoff_row[\"lat\"])\n",
    "\n",
    "        try:\n",
    "            # Call ORS directions API\n",
    "            route = ors_client.directions(\n",
    "                coordinates=[pickup_coords, dropoff_coords],\n",
    "                profile='driving-car',\n",
    "                format='geojson'\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return scatter_map_fig, f\"üü¶ Pickup: {pickup}\", f\"üü© Dropoff: {dropoff}\", html.Div(\n",
    "                \"‚ö†Ô∏è Routing error: ORS is unavailable, please select points that can be routed to eachother by taxi\",\n",
    "                style={\"color\": \"red\", \"fontWeight\": \"bold\"}\n",
    "            )\n",
    "        # Extract distance between points (in meters) and convert to miles\n",
    "        distance_meters = route[\"features\"][0][\"properties\"][\"segments\"][0][\"distance\"]\n",
    "        distance_miles = distance_meters * 0.000621371\n",
    "\n",
    "        # Convert from int to string and vice-versa\n",
    "        shift_int = 0\n",
    "        if shift == 'Rush Hour':\n",
    "            shift_int = 1\n",
    "        elif shift == 'Mid Day':\n",
    "            shift_int = 2\n",
    "        elif shift == 'Night Shift':\n",
    "            shift_int = 3\n",
    "        else:\n",
    "            shift_int = 0\n",
    "\n",
    "        # Supply LocationId for 1) pickup and 2) dropoff, the selected shift, and distance between points\n",
    "        # Calculate estimated fare and time\n",
    "        model_input = [[pickup_row[\"LocationID\"], dropoff_row[\"LocationID\"], shift_int, distance_miles]]\n",
    "        pred_fare = float(np.exp(mlp_models[f\"mlp_fare_{year_selection}\"].predict(model_input)))\n",
    "        pred_time = float(np.exp(mlp_models[f\"mlp_time_{year_selection}\"].predict(model_input)))\n",
    "\n",
    "        # Display trip details for user\n",
    "        hover_text = (\n",
    "            f\"<b>üöñ Trip Info</b><br>\"\n",
    "            f\"üìç From: {pickup}<br>\"\n",
    "            f\"‚û°Ô∏è To: {dropoff}<br>\"\n",
    "            f\"üïê Shift: {shift}<br>\"\n",
    "            f\"üìè Distance: {distance_miles:.2f} mile(s)<br>\"\n",
    "            f\"üíµ Fare per Mile: ${pred_fare:.2f}<br>\"\n",
    "            f\"üïí Time: {pred_time:.1f} min\"\n",
    "        )\n",
    "\n",
    "        # Draw line between points\n",
    "        scatter_map_fig.add_trace(go.Scattermap(\n",
    "            mode=\"lines+markers\",\n",
    "            lat=[pickup_row[\"lat\"], dropoff_row[\"lat\"]],\n",
    "            lon=[pickup_row[\"lon\"], dropoff_row[\"lon\"]],\n",
    "            marker=dict(size=12, color=\"green\"),\n",
    "            line=dict(width=3, color=\"green\"),\n",
    "            hoverinfo=\"text\",\n",
    "            hovertext=hover_text,\n",
    "            showlegend=False,\n",
    "            name=\"Trip Route\"\n",
    "        ))\n",
    "\n",
    "    scatter_map_fig.update_layout(clickmode='event+select')\n",
    "    \n",
    "    pickup_msg = f\"üü¶ Pickup: {pickup}\" if pickup else f\"üü¶ Click on map to select pickup\"\n",
    "    dropoff_msg = f\"üü© Dropoff: {dropoff}\" if dropoff else f\"üü© Click on map to select dropoff\"\n",
    "    return scatter_map_fig, pickup_msg, dropoff_msg, ors_status_msg\n",
    "\n",
    "# --- Run the App ---\n",
    "if __name__ == '__main__':\n",
    "    if 'app' in locals() and isinstance(app, dash.Dash) and zone_time_stats_gdf is not None and scatter_data_df is not None:\n",
    "        print(\"Starting Dash server...\")\n",
    "        print(\"Access the dashboard in your web browser at http://127.0.0.1:8053/\")\n",
    "        app.run(port=8053, debug=True)\n",
    "    else:\n",
    "        print(\"Dash server not started. Check console for data loading errors.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
